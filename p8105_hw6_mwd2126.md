p8105_hw6_mwd2126.Rmd
================
Michael Denham
2022-12-03

### Problem 1

To perform a bootstrap for linear regression with `tmax` as the response
variable and `tmin` as the predictor variable, we can use the following
code. First, we download the weather data.

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

    ## using cached file: ~/Library/Caches/R/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2022-12-04 09:11:51 (8.428)

    ## file min/max dates: 1869-01-01 / 2022-12-31

Then, we set the number of bootstrap samples and make empty vectors to
store the bootstrap estimates.

``` r
n_bootstrap = 5000
r2_bootstrap = numeric(n_bootstrap)
log_beta0beta1_bootstrap = numeric(n_bootstrap)
```

Then we start bootstrap sampling.

``` r
for (i in 1:n_bootstrap){

  #Sample with replacement from the original data
  bootstrap_sample = sample(1:nrow(weather_df), replace = TRUE)
  
  #Fit a linear regression model on the bootstrap sample
  bootstrap_model = lm(tmax ~ tmin, data = weather_df[bootstrap_sample, ])
  
  #Extract r2 and log(beta0 * beta1) from the bootstrap model
  r2_bootstrap[i] = broom::glance(bootstrap_model)$r.squared
  log_beta0beta1_bootstrap[i] = log(coef(bootstrap_model)[1] * coef(bootstrap_model)[2])
  
}
```

Then we plot the distribution of our bootstrap estimates.

``` r
#For r2_bootstrap
r2_bootstrap %>%
  data.frame() %>% 
  ggplot(aes(x = r2_bootstrap)) +
  geom_density() +
  labs(
    title = "Distribution of R-squared Estimates"
  )
```

<img src="p8105_hw6_mwd2126_files/figure-gfm/plot bootstrap-1.png" width="90%" />

``` r
#For log_beta0beta1_bootstrap
log_beta0beta1_bootstrap %>%
  data.frame() %>% 
  ggplot(aes(x = log_beta0beta1_bootstrap)) +
  geom_density() +
  labs(
    title = "Distribution of log(beta0 * beta1) Estimates"
  )
```

<img src="p8105_hw6_mwd2126_files/figure-gfm/plot bootstrap-2.png" width="90%" />

The resulting plots show the distribution of r2 and log(beta0 \* beta1)
estimates obtained from the bootstrap samples. They show that the value
of `r2_bootstrap` is generally around 0.91 and the value of
`log_beta0beta1_bootstrap` is generally around 2.01.

Now, we calculate 95% confidence intervals for r2 and log(beta0 \*
beta1). The 95% confidence intervals for these two quantities can be
calculated by taking the 2.5% and 97.5% quantiles of the bootstrap
estimates.

``` r
r2_ci = quantile(r2_bootstrap, c(0.025, 0.975))

log_beta0beta1_ci = quantile(log_beta0beta1_bootstrap, c(0.025, 0.975))
```

In this case, the 95% confidence interval for `r2_bootstrap` is \[0.894,
0.927\] and the 95% confidence interval for `log_beta0beta1_bootstrap`
is \[1.965, 2.059\].

### Problem 2

First, we’ll start by importing the data from the Washington Post’s
Github page.

``` r
homicide <- read.csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv")
```

We can then create the `city_state` variable by combining the city and
state columns, and create the binary variable `solved` indicating
whether the homicide is solved by using the `ifelse()` function to
assign 1 to homicides that are solved and 0 to those that are not.

``` r
homicide = homicide %>% 
  mutate(
    city_state = str_c(city, ", ", state),
    resolved = ifelse(homicide$disposition == "Closed by arrest", 1, 0)
  )
```

Then we’ll remove Dallas, TX; Phoenix, AZ; and Kansas City, MO because
they don’t report victim race and omit Tulsa, AL because this is a data
entry mistake. We’ll also remove any rows where the victim wasn’t white
or black and make sure the victim’s age is numeric.

``` r
homicide = homicide %>% 
    filter(city_state != "Dallas, TX" && city_state != "Phoenix, AZ" && city_state != "Kansas City, MO" && city_state != "Tulsa, AL") %>% 
  filter(victim_race == "White" | homicide$victim_race == "Black") %>% 
  filter(victim_age != "Unknown")

homicide$victim_age = as.numeric(homicide$victim_age)
```

We’ll make a data frame including only victims in Baltimore, selecting
for the variables we’ll need in our subsequent analysis.

``` r
baltimore = homicide %>% 
  filter(city_state == "Baltimore, MD") %>% 
  select(resolved, victim_age, victim_sex, victim_race)
```

Now, we’ll run a generalized linear regression with resolved vs
unresolved as the outcome and victim age, sex and race as predictors.

``` r
fit_logistic = 
  baltimore %>% 
  glm(resolved ~ victim_age + victim_sex + victim_race , data = ., family = binomial())

fit_logistic = fit_logistic %>%
  broom::tidy() %>%
  mutate(OR = exp(estimate)) %>%
  select(term, log_OR = estimate, OR, p.value) %>% 
  knitr::kable(digits = 3)
```

The adjusted odds ratio for solving homicides comparing male victims to
female victims keeping all other variables fixed is 0.426, with a
confidence interval of \[0.564, 0.288\], suggesting that in Baltimore
homicides with male victims are less likely to be solved compared to
those with female victims.

### Problem 3
